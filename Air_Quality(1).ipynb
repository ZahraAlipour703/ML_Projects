{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "315saHx1i7_2"
      },
      "outputs": [],
      "source": [
        "#Data analysis libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# libraries for models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from pandas.core.common import random_state\n",
        "from sklearn.model_selection import train_test_split\n",
        "#preprocess libraries\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#visulization libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.offline as py\n",
        "from plotly.offline import iplot, init_notebook_mode\n",
        "from plotly.graph_objs import  Scatter\n",
        "py.init_notebook_mode(connected=True)\n",
        "from matplotlib import legend\n",
        "import random\n",
        "%matplotlib inline\n",
        "#General modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#For model evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "#For q-q plot\n",
        "import scipy.stats as stats\n",
        "!pip install keras\n",
        "!pip install scikeras\n",
        "!pip install keras-tuner --upgrade\n",
        "!pip install tensorflow --upgrade\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras import optimizers\n",
        "# metrics evaluation libraries\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import  RandomizedSearchCV\n",
        "#neural\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/AirQualityUCI.csv')"
      ],
      "metadata": {
        "id": "HIQj6AOcMIPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "3T22dCmCMhbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "MUE-BjZuSXV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#droping end rows with NaN values\n",
        "data.dropna(how='all',inplace=True)"
      ],
      "metadata": {
        "id": "yJY2tM0CSSZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "VAUHwpTBSa0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.duplicated()"
      ],
      "metadata": {
        "id": "kQnC395-Sm87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "frJtlD0wSqi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "VPmMAmW6S231"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['Unnamed: 15','Unnamed: 16'], axis=1, inplace=True, errors = 'ignore')"
      ],
      "metadata": {
        "id": "QOuIyILVoMUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percent_NaN = []\n",
        "columns = data.columns\n",
        "for col in columns:\n",
        "    pNaN =  (data[col].isna().sum()/data.shape[0]) * 100 #sum NaN instances in each column. Divide by total rows\n",
        "    percent_NaN.append(pNaN)\n",
        "nan_percent_df = pd.DataFrame(percent_NaN,\n",
        "                              index=columns,\n",
        "                              columns=['%_NaN_in_Column']).sort_values('%_NaN_in_Column',ascending = False)\n",
        "nan_percent_df"
      ],
      "metadata": {
        "id": "KazosTkZokVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning Up Time Features"
      ],
      "metadata": {
        "id": "APXoMS2jpRwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "#Defining Month from DATE column\n",
        "data['Date'] = pd.to_datetime(data.Date, format='%d-%m-%Y')\n",
        "data['MONTH'] = data['Date'].dt.month\n",
        "#Splitting Column TIME(HH:MM:SS) into new column(of int64 type)\n",
        "data['HOUR']=data['Time'].apply(lambda x: int(x.split(':')[0]))\n",
        "data.drop(['Date', 'Time'], axis = 1, inplace = True)\n",
        "data.head(10)\n"
      ],
      "metadata": {
        "id": "xWW2HBheuBKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "7KNqaHobqPaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Removing Outliers From Dataframe"
      ],
      "metadata": {
        "id": "PSPlEbRRvht5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "# Plotting Box and Distribution plot\n",
        "for var in data:\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.subplot(1,2,1)\n",
        "    ax=sns.boxplot(data=data[var], color = 'pink')\n",
        "    ax.set_title(f'{var}')\n",
        "    ax.set_ylabel(var)\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    ax=sns.distplot(data[var], fit=norm, color = 'pink')\n",
        "    ax.set_title(f'skewness of {var} : {data[var].skew()}')\n",
        "    ax.set_xlabel(var)\n",
        "    print('__'*50)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "PwvJkMupWank"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Outliers with the Interquartile Range Method (IQR)\n",
        "Q1 = data.quantile(0.25, numeric_only=True)  # First quartile (25%)\n",
        "Q3 = data.quantile(0.75, numeric_only=True)  # Third quartile (75%)\n",
        "\n",
        "\n",
        "IQR = Q3 - Q1 #IQR = InterQuartile Range\n",
        "\n",
        "scale = 1.4 #May need to play with this value to modify outlier detection sensitivity if need be\n",
        "lower_lim = Q1 - scale*IQR\n",
        "upper_lim = Q3 + scale*IQR\n",
        "cols=[col for col in data.columns if col not in [\"Hour\", \"Month\", \"RH\"]]\n",
        "# cols = data.columns[5:]  # Look for outliers in columns starting from CO(GT)\n",
        "\n",
        "# Align lower_lim and upper_lim with the DataFrame columns\n",
        "lower_lim = lower_lim[cols]\n",
        "upper_lim = upper_lim[cols]\n",
        "\n",
        "# Mask a condition that removes rows with values above/below IQR limits\n",
        "condition = ~((data[cols] < lower_lim) | (data[cols] > upper_lim)).any(axis=1)\n",
        "\n",
        "# Generate a new DataFrame with outliers removed\n",
        "data_filtered = data[condition]"
      ],
      "metadata": {
        "id": "SobjSARNuYsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var in data_filtered:\n",
        "    plt.figure(figsize=(15,6))\n",
        "    plt.subplot(1,2,1)\n",
        "    ax=sns.boxplot(data=data_filtered[var], color = 'pink')\n",
        "    ax.set_title(f'{var}')\n",
        "    ax.set_ylabel(var)\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    ax=sns.distplot(data_filtered[var], fit=norm, color = 'pink')\n",
        "    ax.set_title(f'skewness of {var} : {data_filtered[var].skew()}')\n",
        "    ax.set_xlabel(var)\n",
        "    print('__'*50)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "R9augvXtYDJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols =  list(data.columns)\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(1, 9):\n",
        "    plt.subplot(3, 4, i)\n",
        "    sns.scatterplot(x = cols[i - 1], y = data['RH'],data = data, palette = \"husl\")"
      ],
      "metadata": {
        "id": "eKrEC7DaG412"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairplot1 = sns.pairplot(data, hue='RH')\n",
        "pairplot1.fig.suptitle(\"Water Potability Pairwise Plots\",fontsize=26, y=1.01);"
      ],
      "metadata": {
        "id": "lcfYGqE7PrlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation = data.corr()\n",
        "matrix_cols = correlation.columns.tolist()\n",
        "corr_array  = np.array(correlation)\n",
        "pd.DataFrame(corr_array)"
      ],
      "metadata": {
        "id": "jZc2xVDUS6fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing the correlation\n",
        "plt.figure(figsize = (15, 5))\n",
        "sns.heatmap(correlation, annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DzmbFHZVTI7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing the data"
      ],
      "metadata": {
        "id": "uI67YePcagN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.drop(columns = 'RH')\n",
        "y = data['RH']\n",
        "#scaling\n",
        "scalar = StandardScaler()\n",
        "x = scalar.fit_transform(x)\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "id": "oAur8f69YeT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 18)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "jCuX8QsiTrt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data-Size\n",
        "print('Training Data Size:',x_train.shape)\n",
        "print('Test Data Size:',x_test.shape)"
      ],
      "metadata": {
        "id": "v-OTSwryaYMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build and Train Model Function"
      ],
      "metadata": {
        "id": "3i1XhjH1bZhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression"
      ],
      "metadata": {
        "id": "3w8U-Ko6rsHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= LinearRegression()\n",
        "model.fit(x_train,y_train)\n",
        "prediction = model.predict(x_test)\n",
        "MAE_L =  metrics.mean_absolute_error(y_test, prediction)\n",
        "print('MAE:', MAE_L)\n",
        "MSE_L = metrics.mean_squared_error(y_test, prediction)\n",
        "print('MSE:', MSE_L)\n",
        "RMSE_L = np.sqrt(metrics.mean_squared_error(y_test, prediction))\n",
        "print('RMSE:', RMSE_L)"
      ],
      "metadata": {
        "id": "yN8VjmqJrscD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Actual vs Predicted values\n",
        "plt.figure(figsize=(14, 6))\n",
        "# Plot 1: Actual vs Predicted\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, prediction, alpha=0.7, color='blue', edgecolors='k')\n",
        "plt.xlabel('Actual Values', fontsize=12)\n",
        "plt.ylabel('Predicted Values', fontsize=12)\n",
        "plt.title('Actual vs Predicted Values', fontsize=14)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)  # Diagonal line\n",
        "plt.grid(True)\n",
        "plt.xlim(y_test.min() - 1, y_test.max() + 1)\n",
        "plt.ylim(y_test.min() - 1, y_test.max() + 1)\n",
        "\n",
        "# Annotate metrics\n",
        "plt.annotate(f'MSE: {MSE_L:.2f}\\nMAE: {MAE_L:.2f}\\nRMSE: {RMSE_L:.2f}',\n",
        "             xy=(0.05, 0.95), xycoords='axes fraction',\n",
        "             fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "seUK0E9lrFMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Support Vector Machine"
      ],
      "metadata": {
        "id": "lkio56KPkI5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn import metrics\n",
        "model = SVR()\n",
        "model.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "MAE_S =  metrics.mean_absolute_error(y_test, prediction)\n",
        "print('MAE:', MAE_S)\n",
        "MSE_S = metrics.mean_squared_error(y_test, prediction)\n",
        "print('MSE:', MSE_S)\n",
        "RMSE_S = np.sqrt(metrics.mean_squared_error(y_test, prediction))\n",
        "print('RMSE:', RMSE_S)"
      ],
      "metadata": {
        "id": "ltKbOVt7kNlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Actual vs Predicted values\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot 1: Actual vs Predicted\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, prediction, alpha=0.7, color='pink', edgecolors='k')\n",
        "plt.xlabel('Actual Values', fontsize=12)\n",
        "plt.ylabel('Predicted Values', fontsize=12)\n",
        "plt.title('Actual vs Predicted Values', fontsize=14)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)  # Diagonal line\n",
        "plt.grid(True)\n",
        "plt.xlim(y_test.min() - 1, y_test.max() + 1)\n",
        "plt.ylim(y_test.min() - 1, y_test.max() + 1)\n",
        "\n",
        "# Annotate metrics\n",
        "plt.annotate(f'MSE: {MSE_S:.2f}\\nMAE: {MAE_S:.2f}\\nRMSE: {RMSE_S:.2f}',\n",
        "             xy=(0.05, 0.95), xycoords='axes fraction',\n",
        "             fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NOzPk8ybChEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest Regression"
      ],
      "metadata": {
        "id": "oxPMGGHuksGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model=RandomForestRegressor()\n",
        "model.fit(x_train, y_train)\n",
        "prediction=model.predict(x_test)\n",
        "MAE_R =  metrics.mean_absolute_error(y_test, prediction)\n",
        "print('MAE:', MAE_R)\n",
        "MSE_R = metrics.mean_squared_error(y_test, prediction)\n",
        "print('MSE:', MSE_R)\n",
        "RMSE_R = np.sqrt(metrics.mean_squared_error(y_test, prediction))\n",
        "print('RMSE:', RMSE_R)"
      ],
      "metadata": {
        "id": "xerVxC9IlCfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Actual vs Predicted values\n",
        "plt.figure(figsize=(14, 6))\n",
        "# Plot 1: Actual vs Predicted\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, prediction, alpha=0.7, color='magenta', edgecolors='k')\n",
        "plt.xlabel('Actual Values', fontsize=12)\n",
        "plt.ylabel('Predicted Values', fontsize=12)\n",
        "plt.title('Actual vs Predicted Values', fontsize=14)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)  # Diagonal line\n",
        "plt.grid(True)\n",
        "plt.xlim(y_test.min() - 1, y_test.max() + 1)\n",
        "plt.ylim(y_test.min() - 1, y_test.max() + 1)\n",
        "\n",
        "# Annotate metrics\n",
        "plt.annotate(f'MSE: {MSE_R:.2f}\\nMAE: {MAE_R:.2f}\\nRMSE: {RMSE_R:.2f}',\n",
        "             xy=(0.05, 0.95), xycoords='axes fraction',\n",
        "             fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oe9iu_2ECpiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree Regression"
      ],
      "metadata": {
        "id": "IbCaePXtlbg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(x_train, y_train)\n",
        "prediction = model.predict(x_test)\n",
        "MAE_D =  metrics.mean_absolute_error(y_test, prediction)\n",
        "print('MAE:', MAE_D)\n",
        "MSE_D = metrics.mean_squared_error(y_test, prediction)\n",
        "print('MSE:', MSE_D)\n",
        "RMSE_D = np.sqrt(metrics.mean_squared_error(y_test, prediction))\n",
        "print('RMSE:', RMSE_D)"
      ],
      "metadata": {
        "id": "QDUXSihEq8ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Actual vs Predicted values\n",
        "plt.figure(figsize=(14, 6))\n",
        "# Plot 1: Actual vs Predicted\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, prediction, alpha=0.7, color='orange', edgecolors='k')\n",
        "plt.xlabel('Actual Values', fontsize=12)\n",
        "plt.ylabel('Predicted Values', fontsize=12)\n",
        "plt.title('Actual vs Predicted Values', fontsize=14)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)  # Diagonal line\n",
        "plt.grid(True)\n",
        "plt.xlim(y_test.min() - 1, y_test.max() + 1)\n",
        "plt.ylim(y_test.min() - 1, y_test.max() + 1)\n",
        "\n",
        "# Annotate metrics\n",
        "plt.annotate(f'MSE: {MSE_D:.2f}\\nMAE: {MAE_D:.2f}\\nRMSE: {RMSE_D:.2f}',\n",
        "             xy=(0.05, 0.95), xycoords='axes fraction',\n",
        "             fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I7n7_EqxCuYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Evaluation Metrics\n",
        "\n",
        "Three common evaluation metrics for regression problems:\n",
        "\n",
        "    Mean Absolute Error (MAE) is the mean of the absolute value of the errors:\n",
        "    <math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
        "  <mfrac>\n",
        "    <mn>1</mn>\n",
        "    <mi>n</mi>\n",
        "  </mfrac>\n",
        "  <munderover>\n",
        "    <mo data-mjx-texclass=\"OP\">&#x2211;</mo>\n",
        "    <mrow data-mjx-texclass=\"ORD\">\n",
        "      <mi>i</mi>\n",
        "      <mo>=</mo>\n",
        "      <mn>1</mn>\n",
        "    </mrow>\n",
        "    <mi>n</mi>\n",
        "  </munderover>\n",
        "  <mo data-mjx-texclass=\"ORD\" stretchy=\"false\">|</mo>\n",
        "  <msub>\n",
        "    <mi>y</mi>\n",
        "    <mi>i</mi>\n",
        "  </msub>\n",
        "  <mo>&#x2212;</mo>\n",
        "  <msub>\n",
        "    <mrow data-mjx-texclass=\"ORD\">\n",
        "      <mover>\n",
        "        <mi>y</mi>\n",
        "        <mo stretchy=\"false\">^</mo>\n",
        "      </mover>\n",
        "    </mrow>\n",
        "    <mi>i</mi>\n",
        "  </msub>\n",
        "  <mo data-mjx-texclass=\"ORD\" stretchy=\"false\">|</mo>\n",
        "</math>\n",
        "\n",
        "    Mean Squared Error (MSE) is the mean of the squared errors, MSE \"punishes\" larger errors, which tends to be useful in the real world:\n",
        "    <math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
        "  <mfrac>\n",
        "    <mn>1</mn>\n",
        "    <mi>n</mi>\n",
        "  </mfrac>\n",
        "  <munderover>\n",
        "    <mo data-mjx-texclass=\"OP\">&#x2211;</mo>\n",
        "    <mrow data-mjx-texclass=\"ORD\">\n",
        "      <mi>i</mi>\n",
        "      <mo>=</mo>\n",
        "      <mn>1</mn>\n",
        "    </mrow>\n",
        "    <mi>n</mi>\n",
        "  </munderover>\n",
        "  <mo stretchy=\"false\">(</mo>\n",
        "  <msub>\n",
        "    <mi>y</mi>\n",
        "    <mi>i</mi>\n",
        "  </msub>\n",
        "  <mo>&#x2212;</mo>\n",
        "  <msub>\n",
        "    <mrow data-mjx-texclass=\"ORD\">\n",
        "      <mover>\n",
        "        <mi>y</mi>\n",
        "        <mo stretchy=\"false\">^</mo>\n",
        "      </mover>\n",
        "    </mrow>\n",
        "    <mi>i</mi>\n",
        "  </msub>\n",
        "  <msup>\n",
        "    <mo stretchy=\"false\">)</mo>\n",
        "    <mn>2</mn>\n",
        "  </msup>\n",
        "</math>\n",
        "\n",
        "    Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors, RMSE is interpretable in the \"y\" units:\n",
        "    <math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
        "  <msqrt>\n",
        "    <mfrac>\n",
        "      <mn>1</mn>\n",
        "      <mi>n</mi>\n",
        "    </mfrac>\n",
        "    <munderover>\n",
        "      <mo data-mjx-texclass=\"OP\">&#x2211;</mo>\n",
        "      <mrow data-mjx-texclass=\"ORD\">\n",
        "        <mi>i</mi>\n",
        "        <mo>=</mo>\n",
        "        <mn>1</mn>\n",
        "      </mrow>\n",
        "      <mi>n</mi>\n",
        "    </munderover>\n",
        "    <mo stretchy=\"false\">(</mo>\n",
        "    <msub>\n",
        "      <mi>y</mi>\n",
        "      <mi>i</mi>\n",
        "    </msub>\n",
        "    <mo>&#x2212;</mo>\n",
        "    <msub>\n",
        "      <mrow data-mjx-texclass=\"ORD\">\n",
        "        <mover>\n",
        "          <mi>y</mi>\n",
        "          <mo stretchy=\"false\">^</mo>\n",
        "        </mover>\n",
        "      </mrow>\n",
        "      <mi>i</mi>\n",
        "    </msub>\n",
        "    <msup>\n",
        "      <mo stretchy=\"false\">)</mo>\n",
        "      <mn>2</mn>\n",
        "    </msup>\n",
        "  </msqrt>\n",
        "</math>\n",
        "\n"
      ],
      "metadata": {
        "id": "E_hwGEBiLqfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Network"
      ],
      "metadata": {
        "id": "wTNYeU4ry6Z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim = x_train.shape[1], activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation = 'linear'))  # Linear activation for regression\n",
        "\n",
        "# Compile the model with appropriate loss function for regression\n",
        "model.compile(optimizer = Adam(learning_rate=0.001), loss = 'mean_squared_error', metrics = ['mae'])\n",
        "\n",
        "# Set up early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 5, min_lr = 1e-6)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs = 100, batch_size = 32,\n",
        "                    validation_split = 0.2, callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(x_test, y_test)\n",
        "rmse = np.sqrt(loss)  # Calculate RMSE\n",
        "print(f'Test Loss (MSE): {loss}')\n",
        "print(f'Test Mean Absolute Error (MAE): {mae}')\n",
        "print(f'Test Root Mean Squared Error (RMSE): {rmse}')\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Visualization of Actual vs Predicted values\n",
        "plt.figure(figsize = (12, 6))\n",
        "\n",
        "# Plot 1: Actual vs Predicted\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, predictions)\n",
        "plt.xlabel('Actual RH')\n",
        "plt.ylabel('Predicted RH')\n",
        "plt.title('Actual vs Predicted RH')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Diagonal line\n",
        "\n",
        "# Plot 2: Training History\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TymPD4wgngkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Evaluation"
      ],
      "metadata": {
        "id": "CL81J-kBz5QM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample results from different models\n",
        "rsl = {'MAE': MAE_L, 'MSE': MSE_L, 'RMSE': RMSE_L} #Linear Regression\n",
        "rsd = {'MAE': MAE_D, 'MSE': MSE_D, 'RMSE': RMSE_D}  # Decision Tree Regression\n",
        "rsr = {'MAE': MAE_R, 'MSE': MSE_R, 'RMSE': RMSE_R}  # Random Forest Regression\n",
        "rss = {'MAE': MAE_S, 'MSE': MSE_S, 'RMSE': RMSE_S}  # Support Vector Machine Regression\n",
        "rsn = {'MAE': mae, 'MSE': loss, 'RMSE': rmse} # \"Neural Network\"\n",
        "\n",
        "# Dictionary to hold results\n",
        "results_dict = {\n",
        "    \"Linear Regression\": rsl,\n",
        "    \"Decision Tree Regression\": rsd,\n",
        "    \"Random Forest Regression\": rsr,\n",
        "    \"Support Vector Machine Regression\": rss,\n",
        "    \"Neural Network\" : rsn\n",
        "}\n",
        "\n",
        "# Find the best model based on the minimum values for MAE, MSE, and RMSE\n",
        "best_models = {}\n",
        "for metric in ['MAE', 'MSE', 'RMSE']:\n",
        "    best_value = min(results_dict[model][metric] for model in results_dict)\n",
        "    best_models[metric] = [model for model in results_dict if results_dict[model][metric] == best_value]\n",
        "\n",
        "# Print the best results\n",
        "print(\"So we achieve best results from:\")\n",
        "for metric, models in best_models.items():\n",
        "    print(f\"{metric}: {', '.join(models)} with value: {best_value}\")\n",
        "\n",
        "# Optionally, print the overall best model based on the lowest RMSE\n",
        "overall_best_model = min(results_dict, key=lambda x: results_dict[x]['RMSE'])\n",
        "print(f\"\\nOverall Best Model based on RMSE: {overall_best_model} with RMSE: {results_dict[overall_best_model]['RMSE']}\")\n"
      ],
      "metadata": {
        "id": "GgEiurGqzz9J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}